---
title: 持续 AI 的实践：开发者今天能用“代理式 CI”自动化哪些工作
date: '2026-02-07T00:31:09.712Z'
sourceUrl: >-
  https://github.blog/ai-and-ml/generative-ai/continuous-ai-in-practice-what-developers-can-automate-today-with-agentic-ci/
lang: zh
---
软件工程里一直存在一些重复、必要、但在历史上很难自动化的工作。并不是因为这些工作没有价值，而是因为它们很难被还原成确定性的规则。

持续集成（CI）通过承接测试、构建、格式化、静态分析等工作，解决了其中一部分——也就是任何能够用确定性规则描述的事情。只要“正确性”能被明确表达，CI 就很擅长：测试通过或失败、构建成功或失败、规则被违反或没有。

但 CI 也刻意把自己限制在那些可以被简化为启发式与规则的问题上。

对大多数团队来说，最难的工作并不是写代码，而是围绕代码所需要的一切判断：审查变更、保持文档准确、管理依赖、追踪回归、维护测试、监控质量，以及响应那些只有在代码发布后才会暴露的问题。

然而，工程工作里有相当一部分需要的是解释、综合与上下文，而不是确定性的验证；而且越来越多的工程任务落入了 CI 从未被设计去处理的类别：依赖于理解“意图”的工作。

GitHub Next（负责研发探索项目）负责人 Idan Gazit 说：“任何需要判断的任务都超出了启发式的能力边界。”

> 任何无法用规则或流程图表达的地方，都是 AI 变得异常有用的地方。
> 
> Idan Gazit，GitHub Next 负责人

这也是 GitHub Next 在探索一种新模式的原因：[Continuous AI](https://githubnext.com/projects/continuous-ai/)（持续 AI）——一种在你的仓库里像 CI 作业那样运行的“后台代理”，但它处理的是需要推理而不是规则的任务。

## 为什么 CI 已经不够了

CI 并没有失败。它只是准确地在做自己被设计来做的事情。

CI 的设计目标是二元结果：测试通过或失败；构建成功或失败；linter 标出定义明确的违规项或不标。这对基于规则的自动化非常有效。

但很多最难、最耗时的工程工作，都高度依赖判断、并且强上下文相关。

想想这些场景：

* 一个 docstring 写的是一回事，实现却是另一回事。
* 文本通过了可访问性 lint，但用户仍然觉得难以理解。
* 一个依赖新增了 flag，却没提升主版本号，于是行为悄悄变了。
* 一个正则在循环里被反复编译，性能在不易察觉的地方被拖垮。
* UI 行为变化只有在真实交互时才能看出来。

这些问题的核心是：原本的“意图”是否还成立。

Idan 解释说：“AI 用于代码的第一阶段是代码生成。第二阶段则涉及认知，把那些认知负担很重的杂务从开发者身上卸下来。”

持续 AI 填补的正是这个空缺：不是更多的自动化，而是**另一类**自动化。CI 负责确定性工作；持续 AI 则适用于正确性依赖推理、解释与意图的地方。

## “持续 AI”到底是什么意思

持续 AI 不是一个新产品，也不是用来替代 CI 的。传统 CI 仍然至关重要。

持续 AI 是一种模式：

**持续 AI = 自然语言规则 + 代理式推理，在你的仓库里持续执行。**

实践中，持续 AI 的做法是：用通俗自然的语言表达“你的代码应该满足什么”，尤其是当这种期待无法被还原成规则或启发式时。然后由一个代理去评估仓库，并产出开发者可以审阅的产物：建议的补丁、issue、讨论，或洞察。

开发者很少一次就写出完美的代理式工作流。更常见的是，开发者与代理协作来反复打磨意图、补充约束、定义可接受的输出。工作流是在迭代中长出来的，而不是一句话写完的。

比如：

* “检查文档描述是否与实现一致，解释所有不一致，并给出可执行的修复方案。”
* “生成每周报告：总结项目活动、浮现的 bug 趋势，以及 churn 增加的区域。”
* “标记关键路径上的性能回退。”
* “检测用户流程中的语义回归。”

这些工作流不以“短”取胜，而是把意图、约束与允许的输出组合起来，表达那些用确定性规则会显得别扭、甚至无法编码的期待。

Idan 说：“未来重点不是让代理在你的仓库里跑，而是你可以以很低的成本，为任何你想永久从待办里拿掉的事情定义代理。”

> 想想当你能把更多工作委托给 AI 时，你的工作会变成什么样；以及你希望保留哪些部分：你的判断、你的品味。
> 
> Idan Gazit，GitHub Next 负责人

## 设计层面的护栏：权限与安全输出

在我们的工作中，我们把安全视为定义代理式工作流的第一原则。默认情况下，代理只拥有对仓库的只读访问权限。除非你明确授权，否则它不能创建 issue、打开 PR、或修改内容。

我们把这套机制称为 **Safe Outputs（安全输出）**：它为代理“允许做什么”提供一个确定性的契约。定义工作流时，开发者需要明确代理可以产出哪些工件（例如开 PR 或提 issue），以及在什么约束下才允许这么做。

任何超出边界的行为都是禁止的。

这个模型假设代理可能失败或出现意外行为。因此输出会被净化处理、权限必须显式授予，所有活动都会记录并可审计。影响范围是可控且确定的。

这并不是“AI 接管软件开发”，而是 AI 在开发者明确设定的护栏之内运行。

## 为什么自然语言能补充 YAML

我们在推进这套模式时，经常听到一个问题：为什么不直接扩展 CI，加更多规则？

当一个问题可以确定性地表达时，扩展 CI 的确是正确做法。YAML、schema 与启发式仍然是处理这类工作的正确工具。

但很多期待如果强行还原成规则，就会丢失意义。

Idan 说得很直接：“**有一大类杂务与任务，我们无法用启发式表达。**”

像“当文档与代码不一致时，识别并修复它”这样的规则，无法用正则或 schema 完整表达。它需要理解语义与意图。而自然语言指令可以把这种期待表达得足够清楚，让代理基于它来推理。

自然语言不是用来取代 YAML，而是用来补充它。CI 仍然是基础；持续 AI 则把自动化扩展到 CI 从未被设计去覆盖的领域。

## 开发者始终在环（by design）

代理式工作流不会自动提交合并。相反，它会根据工作流被允许做的事情，产出开发者同样熟悉的工件：PR、issue、评论或讨论。

PR 是最常见的输出形式，因为它契合开发者审查与推理变更的方式。

Idan 说：“PR 是开发者已经习惯用来审查工作的‘名词’。大家会围绕它达成检查点。”

这意味着：

* 代理不会合并代码
* 开发者保留完全控制权
* 一切都是可见、可审阅的

开发者的判断仍然是最终权威。持续 AI 的价值在于，把这种判断能力扩展到整个代码库。

## GitHub Next 如何实验这些想法

[GitHub Next prototype](https://githubnext.github.io/gh-aw/)（你也可以在仓库里找到：[gh aw](https://github.com/githubnext/gh-aw)）使用了一个刻意保持简单的模式：

1. 编写一个代理式工作流
2. 把它编译成一个 GitHub Action
3. 推送到仓库
4. 让代理在任何 GitHub Actions 触发器上运行（PR、push、issue、评论或定时任务）

没有任何隐藏；一切都是透明且可见的。

Idan 解释说：“你希望一个 action 去找样式违规，比如括号位置不对，那是启发式。但当你想做更深层的意图检查时，你就需要 AI。”

## 持续 AI 今天能自动化哪些工作

这些不是理论例子。GitHub Next 已经在真实仓库里测试过这些模式。

### 1. 修复文档与行为不一致

这对 CI 来说是最难的问题之一，因为它需要理解*意图*。

一个代理式工作流可以：

* 读取函数的 docstring
* 把它与实现对比
* 检测不一致
* 建议更新代码或文档
* 打开一个 PR

Idan 认为这是持续 AI 能解决的、最有意义的一类工作：“你不想每次发布代码都担心文档还对不对。在 AI 之前，这是无法自动化的。”

### 2. 用推理生成持续的项目报告

维护者与管理者经常要重复回答同样的问题：昨天改了什么？bug 趋势在上升还是下降？代码库哪些部分最活跃？

代理式工作流可以生成周期性报告：从多个数据源（issue、PR、提交、CI 结果）汇总信息，并在其之上做推理。

例如，代理可以：

* 总结每日或每周活动
* 标出正在出现的 bug 趋势
* 把近期变更与测试失败关联起来
* 指出 churn 增加的区域

价值不在报告本身，而在跨多个数据源的综合——否则这通常需要手工分析。

### 3. 自动保持翻译同步

做过本地化的人都熟悉这个模式：英文内容变了，翻译落后，团队最后在周期末（往往是发版前）集中补翻译。

代理可以：

* 检测英文文本变化
* 为所有语言重新生成翻译
* 打开一个包含所有更新的 PR

工作流因此变成连续的，而不是阶段性集中处理的。机器翻译未必完美，但当 PR 里已经有了可审阅的草稿翻译，专业翻译或社区贡献者就更容易参与。

### 4. 检测依赖漂移与未记录的变更

依赖常常在不提升主版本号的情况下改变行为：新 flag 出现、默认值变化、help 输出演进。

在一个 demo 中，代理：

* 安装依赖
* 检查 CLI help 文本
* 与前几天对比 diff
* 发现一个未记录的 flag
* 在维护者注意到之前就先提了一个 issue

这需要语义层面的解释，而不只是 diff，所以传统 CI 做不到。

Idan 说：“这是 AI 新阶段的第一个征兆。我们正在从生成走向推理。”

### 5. 自动化测试覆盖率燃尽

在一个实验里：

* 测试覆盖率从约 5% 提升到接近 100%
* 编写了 1,400+ 个测试
* 持续了 45 天
* token 成本约 ~$80

而且因为代理每天产出小的 PR，开发者可以增量地审查变更。

### 6. 后台性能改进

linter 与分析器不一定能抓到那些依赖“意图理解”的性能陷阱。

例如：在函数调用里编译正则，导致每次调用都要重新编译。

代理可以：

* 识别低效点
* 重写代码，把正则预编译
* 打开一个 PR，并解释原因

这些“小事”会累积，尤其是在高频调用路径里。

### 7. 自动化交互测试（把代理当成确定性的试玩测试员）

这是 Universe 上更有创意的 demo 之一：用代理玩一个简单的平台跳跃游戏上千次，以检测 UX 回归。

把“游戏”抽象掉，这个模式其实很通用：

* 新手引导流程
* 多步骤表单
* 重试循环
* 输入校验
* 交互下的可访问性模式

代理可以在规模化地模拟用户行为，并对比不同版本。

## 如何构建你的第一个代理式工作流

开发者不需要新的 CI 系统或单独的基础设施就能尝试。GitHub Next 的原型（gh aw）使用一个简单模式：

**1. 在一个 Markdown 文件里写下自然语言规则**

例如：

```plaintext
---
on: daily
permissions: read
safe-outputs:
  create-issue:
    title-prefix: "[news] "
---
Analyze the recent activity in the repository and:
- create an upbeat daily status report about the activity
- proviate an agentic task description to improve the project based on the activity.
Create an issue with the report.
```

**2. 把它编译成一个 action**

```plaintext
gh aw compile daily-team-status
```

这会生成一个 GitHub Actions workflow。

**3. 审查 YAML**

没有任何隐藏。你可以清楚看到代理会做什么。

**4. 推送到你的仓库**

代理式工作流会响应你定义的仓库事件或定时计划开始执行，**就像任何其它 action 一样**。

**5. 审查它创建的 issue**

## 接下来值得关注的模式

虽然还很早，但开发者工作流中已经出现了几个趋势：

**模式 1：自然语言规则会成为自动化的一部分**

开发者会写一些简短的英文规则来表达意图：

* “保持翻译是最新的”
* “标记性能回退”
* “对看起来不安全的鉴权模式发出警告”

**模式 2：仓库会开始托管一支“小代理舰队”**

不是一个通用代理，而是很多小代理；每个代理负责一个杂务、一个检查、或一个经验法则。

**模式 3：测试、文档、本地化、清理会转向“持续”模式**

这和早期 CI 运动类似：不是取代开发者，而是把杂务发生的时机从“有人想起来才做”变成“每天都做”。

**模式 4：可调试性会胜过复杂性**

开发者会采用透明、可审计、基于 diff 的代理式模式，而不是那些不透明、在不可见处行动的系统。

## 开发者应该带走什么

Idan 说：“持续 AI 就是为那些离线任务定制代理。你以前无法外包的事情，现在都可以。”

**更准确地说：许多过去必须手工做的、重判断的杂务，如今可以变成持续的。**

这需要一次心智转变，就像从“拥有音乐文件”转向“流媒体”。

Idan 说：“音乐你一直都拥有，但突然播放器开始帮你发现更多。”

## 从一个小工作流开始

持续 AI 不是非此即彼。你不需要彻底改造整个流水线。从小处开始：

* 翻译字符串
* 补齐缺失的测试
* 检查 docstring 漂移
* 检测依赖变化
* 标记那些微妙的性能问题

这些都是代理今天就能有意义地帮助的事情。

找出那些反复出现、却悄悄消耗注意力的“重判断任务”，把它们从阶段性（episodic）变成持续（continuous）。

如果过去十年 CI 自动化了基于规则的工作，那么当持续 AI 被谨慎且安全地应用时，它也可能对某些类别的、基于判断的工作做到同样的事。

## 作者

![GitHub Staff](https://avatars.githubusercontent.com/u/9919?v=4&s=200)

GitHub 是世界上最好的开发者体验平台，并且在每一步都融入了安全能力的 AI 平台，让你能安心创新。
